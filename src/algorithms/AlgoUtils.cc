// (c) Meta Platforms, Inc. and affiliates. Confidential and proprietary.
#include "AlgoUtils.h"

#include <cmath>
#include <utility>

#include "checks.h"
#include "collectives.h"

namespace nccl {
namespace algorithms {

std::pair<dim3, dim3> getGridAndBlockDims(
    const void* func,
    size_t count,
    ncclDataType_t datatype,
    size_t maxBlocks) {
  cudaFuncAttributes funcAttr;
  CUDACHECKIGNORE(cudaWrapper->cudaFuncGetAttributes(&funcAttr, func));

  unsigned int minBlocks = 1;

  unsigned int minThreads = 32; // warp size
  unsigned int maxThreads = funcAttr.maxThreadsPerBlock;

  const size_t dataSize = ncclTypeSize(datatype);
  const size_t elementsPerThread =
      16 / dataSize; // we do 16 Byte load in kernel

  dim3 grid{1, 1, 1};
  dim3 block{1, 1, 1};

  if (count <= minBlocks * minThreads * elementsPerThread) {
    // for small counts, use the minimum number of blocks and
    // threads, while keeping elementsPerThread elements to be
    // computed by each thread.
    grid.x = minBlocks;
    block.x = minThreads;
  } else if (count < minBlocks * maxThreads * elementsPerThread) {
    // for slightly larger counts, increase the number of threads
    // per block to up to the maximum number of threads.
    grid.x = minBlocks;
    block.x =
        static_cast<int>(std::ceil(count / (minBlocks * elementsPerThread)));
  } else if (count < maxBlocks * maxThreads * elementsPerThread) {
    // for even larger counts, increase the number of blocks to up
    // to the maximum number of blocks.
    grid.x =
        static_cast<int>(std::ceil(count / (maxThreads * elementsPerThread)));
    block.x = maxThreads;
  } else {
    // for even larger counts, use the maximum number of threads
    // and blocks, and let each thread compute more elements.
    grid.x = maxBlocks;
    block.x = maxThreads;
  }

  return std::make_pair(grid, block);
}

} // namespace algorithms
} // namespace nccl
